<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">

	<title>Attention Is All You Need 報告</title>

	<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
	<meta name="author" content="Hakim El Hattab">

	<meta name="apple-mobile-web-app-capable" content="yes">
	<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

	<meta name="viewport" content="width=device-width, initial-scale=1.0">

	<link rel="stylesheet" href="css/reset.css">
	<link rel="stylesheet" href="css/reveal.css">
	<link rel="stylesheet" href="css/theme/black.css" id="theme">
	<style>
		@import url("./css/index.css");
	</style>

	<!-- Theme used for syntax highlighting of code -->
	<link rel="stylesheet" href="lib/css/monokai.css">

	<!-- Printing and PDF exports -->
	<script>
		var link = document.createElement('link');
		link.rel = 'stylesheet';
		link.type = 'text/css';
		link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
		document.getElementsByTagName('head')[0].appendChild(link);
	</script>
	<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>
	<script type="text/x-mathjax-config">
        MathJax.Hub.Config({ TeX: { extensions: ["color.js"] }});
	</script>
	<style>
		@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+TC&display=swap');
		@import url('https://fonts.googleapis.com/css2?family=Source+Code+Pro&display=swap');

		section {
			font-family: 'Source Code Pro', 'Noto Sans TC', sans-serif;
		}
	</style>

	<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
</head>

<body>

	<div class="reveal">

		<!-- Any section element inside of this container is displayed as a slide -->
		<div class="slides text-4xl">
			<section>
				<p style="font-size: 150%;">
					<a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a>
				</p>
				<br />
				<p class="text-left pl-24 text-2xl">
					<nobr>Ashish Vaswani</nobr>,
					<nobr>Noam Shazeer</nobr>,
					<nobr>Niki Parmar</nobr>,
					<nobr>Jakob Uszkoreit</nobr>,
					<nobr>Llion Jones</nobr>,
					<nobr>Aidan N. Gomez</nobr>,
					<nobr>Lukasz Kaiser</nobr>,
					<nobr>Illia Polosukhin</nobr>
				</p>
				<p class="text-left pl-24 text-2xl">
					<nobr>The International Conference on <br />Neural Information Processing Systems (NIPS'17),</nobr>
					<nobr>pp. 6000–6010, Dec. 2017</nobr>
				</p>
			</section>

			<!-- 目錄 -->
			<section>
				<h3>目錄</h3>
				<ol>
					<li>
						<p>
							<nobr><a href="index.html#/2">背景知識</a></nobr>
						</p>
					</li>
					<li>
						<p>
							<nobr><a href="index.html#/3">Transformer 簡介</a></nobr>
						</p>
					</li>
					<li>
						<p>
							<nobr><a href="index.html#/4">Multi-Head Attention</a></nobr>
						</p>
					</li>
					<li>
						<p>
							<nobr><a href="index.html#/5">認真拆解 Transformer</a></nobr>
						</p>
					</li>
					<li>
						<p>
							<nobr><a href="index.html#/6">實驗 & 結論</a></nobr>
						</p>
					</li>
					<li>
						<p>
							<nobr><a href="index.html#/7">參考資料</a></nobr>
						</p>
					</li>
					<li>
						<p>
							<nobr><a href="index.html#/8">聊聊</a></nobr>
						</p>
					</li>
				</ol>

			</section>

			<!-- 背景知識 -->
			<section>
				<section>
					<p style="font-size: 150%;">
						背景知識
					</p>
					<ol>
						<li><a href="index.html#/2/1">Attention</a></li>
						<li><a href="index.html#/2/6">Word Embedding</a></li>
					</ol>
				</section>

				<!-- Attention -->
				<section>
					<p style="font-size: 150%;">
						Attention？
					</p>
				</section>

				<section>
					<div class="flex flex-row">
						<div class="w-1/3">
							<video autoplay muted loop>
								<source src="./img/attention.mp4" type="video/mp4">
							</video>
						</div>
						<div>
							<p class="fragment fade-up pl-10 pt-10 text-left">
								你的視線是不是集中在
								<br /> 這隻史萊姆身上？ </p>
						</div>
				</section>

				<section>
					<img src="./img/attention.png" />
				</section>

				<section>
					<p>
						注意力機制「太」簡單的理解就是
					</p>
					<p class="fragment fade-up">
						「賦予剛剛<strong class="text-red-500">標記的位置</strong>較大的權重」
					</p>
					<p class="fragment fade-up text-3xl">
						像是 LSTM 的記憶機制其實就是一種 Attention
					</p>
				</section>

				<section>
					<ol>
						<li>Soft Attention</li>
						<li>Hard Attention</li>
						<li>Local Attention</li>
						<li>Global Attention</li>
						<li>
							<strong class="text-orange-500">Self Attention</strong>
						</li>
					</ol>
					<p class="fragment fade-up">
						今天只會講解 Self Attention
					</p>
				</section>

				<!-- Word Embedding -->
				<section>
					<p style="font-size: 150%;">
						Word Embedding
					</p>
				</section>

				<section>
					<p>
						在 NLP 領域中，要對文本進行前處理
					</p>
					<br />
					<ol class="fragment fade-up">
						<li>建字典</li>
						<li>切文本</li>
						<li>轉換 Symbol</li>
					</ol>
				</section>

				<section>
					<p class="text-left pl-24">
						建字典
					</p>
					<p class="text-left pl-32">
						為所有可能出現的 Symbol 標上 ID
					</p>
				</section>

				<section>
					<p class="text-left pl-24">
						切文本
					</p>
					<p class="text-left pl-32">
						將文本分割成多個 Symbol 並取得其 ID，
						<br /> Symbol 的單位可以是 Token 或是 Character
					</p>
				</section>
				<section>
					<p class="text-left pl-24">
						轉換 Symbol
					</p>
					<ul class="fragment fade-up">
						<li>One Hot Encoding</li>
						<li>Word Embedding</li>
					</ul>
				</section>
				<section>
					<img src="./img/one_hot_encoding.png" /> One Hot Encoding
				</section>
				<section>
					<p class="text-left pl-64">
						缺點
					</p>
					<ul>
						<li class="fragment fade-up">太~大~~</li>
						<li class="fragment fade-up">資訊稀疏</li>
					</ul>
				</section>

				<section>
					<video class="w-5/6 m-auto" autoplay muted loop>
						<source src="./img/word-vector-space_clip.mp4" type="video/mp4">
					</video>
					Word Embedding [<a href="#/7/1">1</a>]
				</section>
				<section>
					<p class="text-left pl-24">Word Embedding 的目標是將詞字轉換到向量空間</p>
					<p class="fragment fade-up text-left pl-24">
						具有相似語意的詞彙轉成的向量會很相似
					</p>
					<p class="fragment fade-up text-left pl-24">
						語言不同但語意相同的詞向量，會遠比相同語言但不同意義的詞向量來的相近
					</p>
				</section>
				<section>
					<img src="./img/embedding_0.png" />建構 Embedding Table(可訓練的權重)
				</section>
				<section>
					<img src="./img/embedding_1.png" /> 查找 Table
				</section>
				<section>
					<img src="./img/embedding_2.png" /> 完成轉換
				</section>
				<section>
					<p class="text-left pl-48">
						優點
					</p>
					<ul>
						<li class="fragment fade-up">較小</li>
						<li class="fragment fade-up">
							資訊緊緻，
							<br /> 可表示出 Symbol 之間的關係
						</li>
					</ul>
				</section>
			</section>

			<!-- Transformer 簡介 -->
			<section>
				<section>
					<p style="font-size: 150%;">
						Transformer 簡介
					</p>
					<p class="fragment fade-up">
						由<strong class="text-red-500">注意力機制</strong>組成的全新架構
					</p>
					<ol>
						<li><a href="#/3/1">Why Transformer ?</a></li>
						<li><a href="#/3/7">使用手冊，以翻譯為例</a></li>
					</ol>
				</section>

				<section>
					<p class="text-left pl-24">
						在 <del>NLP 的領域中</del> 處理時序相關的問題時
					</p>
					<p class="text-left pl-24 fragment fade-up">
						通常會使用 RNN、LSTM 等等架構來解決
					</p>
					<p class="text-left pl-24 fragment fade-up">
						到後來還用上了<strong>注意力機制</strong>
					</p>
				</section>

				<section>
					<img src="./img/rnn.png" /> RNN
				</section>

				<section>
					<p>
						但是這類模型受到並行性限制影響
					</p>
					<p class="fragment fade-up">
						非常的緩～～～～～～～～～～慢
					</p>
				</section>

				<section>
					<p class="text-left pl-24">
						所以在 2017 年，
					</p>
					<p class="text-left pl-24">
						由 Attention 組成
					</p>
					<p class="text-left pl-24">
						全新的架構「Transformer」閃亮登場。
					</p>
				</section>

				<section>
					<p class="text-left pl-24">
						依靠的獨特的 Multi-Head Attention
					</p>
					<p class="text-left pl-24">
						Transformer 獲得了高並行性與充滿彈性的感受野。
					</p>
				</section>

				<section>
					<p class="text-left pl-24">
						<del>自此 RNN 便成為歷史</del>
					</p>
					<p class="text-left pl-24 fragment fade-up">
						並沒有！</p>
					<p class="text-left pl-24 fragment fade-up">後來還轉職成「<a
							href="https://arxiv.org/abs/1901.02860">Transformer XL</a>」的專業輔助
					</p>
					<p class="text-left pl-24 fragment fade-up">
						但這不是今天要聊的（逃</p>
				</section>

				<section>
					<p class="text-left pl-10">
						在正式解構 Transformer 前，<br /> 先從「翻譯任務」介紹其訓練與使用方式。
					</p>
					<p class="text-left pl-10 flex items-center fragment fade-up">
						<span class="pr-10">不然後面會越來越</span><img class="w-64" src="./img/黑人問號.jpg" />
					</p>
				</section>

				<section>
					<p>
						<span class="text-purple-400">Output</span> 的 Sequence length 與 <span
							class="text-orange-400">Target</span> 相同
					</p>
					<img class="" src="./img/black_box.png" /> 輸入與輸出
				</section>

				<section>
					<p>
						在訓練時會先準備兩筆資料
					</p>
					<ul>
						<li><span class="text-green-400">來源文本</span></li>
						<li><span class="text-orange-400">目標文本</span></li>
					</ul>
					<p class="fragment fade-up">
						並將兩者<span class="text-yellow-500">拆成 Symbol </span>後加上
						<br />
						<span class="text-pink-500">「起始符號」</span>與<span class="text-pink-500">「結束符號」</span>
					</p>
				</section>

				<section>
					<p class="text-left pl-10">
						來源文本：<span class="text-green-400">Attention is all you need</span>
					</p>
					<p class="text-left pl-10 fragment fade-up">
						處理後：<br />
						<span class="text-pink-500">&lt;START&gt;</span>,
						<span class="text-green-400">Attention</span>,
						<span class="text-green-400">is</span>,
						<span class="text-green-400">all</span>,
						<span class="text-green-400">you</span>,
						<span class="text-green-400">need</span>,
						<span class="text-pink-500">&lt;END&gt;</span>
					</p>
				</section>

				<section>
					<p class="text-left pl-10">
						目標文本：<span class="text-orange-400">注意力就是你所需要的</span>
					</p>
					<p class="text-left pl-10 fragment fade-up">
						處理後：<br />
						<span class="text-pink-500">&lt;START&gt;</span>,
						<span class="text-orange-400">注意力</span>,
						<span class="text-orange-400">就是</span>,
						<span class="text-orange-400">你</span>,
						<span class="text-orange-400">所</span>,
						<span class="text-orange-400">需要</span>,
						<span class="text-orange-400">的</span>,
						<span class="text-pink-500">&lt;END&gt;</span>
					</p>
				</section>

				<section>
					<p class="text-left pl-10">
						Input：<strong class="text-green-400">來源文本</strong> 轉換成的 <strong class="text-yellow-500">Symbol
							ID</strong> Sequence
					</p>
					<p class="text-left pl-10 fragment fade-up">
						Target：<br />
						<strong class="text-orange-400">目標文本[:-1]</strong> 轉換成的 <strong class="text-yellow-500">Symbol
							ID</strong> Sequence
					</p>
					<p class="text-left pl-10 fragment fade-up">
						Output：預測詞字的 <strong class="text-pink-500">機率分布</strong> 序列
					</p>
					<p class="text-left pl-10 fragment fade-up">
						Ground Truth：<br />
						<strong class="text-orange-400">目標文本[1:]</strong> 的 <strong class="text-pink-500">One Hot
							Encoding</strong> Sequence
					</p>
				</section>
				<section>
					<img src="./img/黑人問號.jpg" />
				</section>

				<section>
					<p class="text-left pl-10">
						Input：
						<br /><span class="text-pink-500">&lt;START&gt;</span>,
						<span class="text-green-400">Attention</span>,
						<span class="text-green-400">is</span>,
						<span class="text-green-400">all</span>,
						<span class="text-green-400">you</span>,
						<span class="text-green-400">need</span>,
						<span class="text-pink-500">&lt;END&gt;</span>
					</p>
					<p class="text-left pl-10">
						Target：
						<br />
						<span class="text-pink-500">&lt;START&gt;</span>,
						<span class="text-orange-400">注意力</span>,
						<span class="text-orange-400">就是</span>,
						<span class="text-orange-400">你</span>,
						<span class="text-orange-400">所</span>,
						<span class="text-orange-400">需要</span>,
						<span class="text-orange-400">的</span>,
						<del class="text-red-600">&lt;END&gt;</del>
					</p>

					<p class="text-left pl-10">
						Ground Truth：
						<br />
						<del class="text-red-600">&lt;START&gt;</del>,
						<span class="text-orange-400">注意力</span>,
						<span class="text-orange-400">就是</span>,
						<span class="text-orange-400">你</span>,
						<span class="text-orange-400">所</span>,
						<span class="text-orange-400">需要</span>,
						<span class="text-orange-400">的</span>,
						<span class="text-pink-500">&lt;END&gt;</span>
					</p>
				</section>

				<section>
					<p class="text-left pl-10">
						講人話就是：
					</p>
					<p class="text-left pl-10">
						希望模型能預測出 <span class="text-orange-400">Target</span> 的下一個字該是什麼
					</p>
				</section>

				<section>
					<img src="./img/usage.png" /> Usage
				</section>

				<section>
					<p class="text-left pl-10">
						在使用時，最開始的 <span class="text-orange-400">Target</span> 只有 <span
							class="text-pink-500">&lt;START&gt;</span>
					</p>
					<p class="text-left pl-10">
						輸入 <span class="text-green-400">Input</span> 與 <span class="text-orange-400">Target</span>
						後可以得到模型預測的
						<br />
						<strong><u class="text-blue-300">下一個字</u></strong><sup style="font-size:1.5rem;"
							class="text-yellow-400">NEW!</sup>
					</p>
				</section>

				<section>
					<p class="text-left pl-10">
						Input：
						<br /><span class="text-pink-500">&lt;START&gt;</span>,
						<span class="text-green-400">Attention</span>,
						<span class="text-green-400">is</span>,
						<span class="text-green-400">all</span>,
						<span class="text-green-400">you</span>,
						<span class="text-green-400">need</span>,
						<span class="text-pink-500">&lt;END&gt;</span>
					</p>
					<p class="text-left pl-10">
						Target：
						<br />
						<span class="text-pink-500">&lt;START&gt;</span>
					</p>
					<p class="fragment fade-up text-left pl-10">
						Output：
						<br />
						<strong><u class="text-blue-300">注意力</u></strong><sup class="text-yellow-400">NEW!</sup>
					</p>
				</section>

				<section>
					<p class="text-left pl-10">
						將預測出的 <strong><u class="text-blue-300">下一個字</u></strong><sup class="text-yellow-400">NEW!</sup>
						接到
						<span class="text-orange-400">Target</span> 後面，<br /> 變成 <span class="text-orange-400">新的
							Target</span>
					</p>
				</section>

				<section>
					<p class="text-left pl-10">
						Input：
						<br /><span class="text-pink-500">&lt;START&gt;</span>,
						<span class="text-green-400">Attention</span>,
						<span class="text-green-400">is</span>,
						<span class="text-green-400">all</span>,
						<span class="text-green-400">you</span>,
						<span class="text-green-400">need</span>,
						<span class="text-pink-500">&lt;END&gt;</span>
					</p>
					<p class="text-left pl-10">
						Target：
						<br />
						<span class="text-pink-500">&lt;START&gt;</span>,
						<span class="text-orange-400">注意力</span>
					</p>
					<p class="fragment fade-up text-left pl-10">
						Output：
						<br />
						<span class="text-orange-400">注意力</span>,
						<strong><u class="text-blue-300">就是</u></strong><sup class="text-yellow-400">NEW!</sup>
					</p>
				</section>
				<section>
					<p class="text-left pl-10">
						不斷重覆到預測出 <span class="text-pink-500">&lt;END&gt;</span> 或到達設定的預測上限次數
					</p>
				</section>
				<section>
					<p class="text-left pl-10">
						Input：
						<br /><span class="text-pink-500">&lt;START&gt;</span>,
						<span class="text-green-400">Attention</span>,
						<span class="text-green-400">is</span>,
						<span class="text-green-400">all</span>,
						<span class="text-green-400">you</span>,
						<span class="text-green-400">need</span>,
						<span class="text-pink-500">&lt;END&gt;</span>
					</p>
					<p class="text-left pl-10">
						Target：
						<br />
						<span class="text-pink-500">&lt;START&gt;</span>,
						<span class="text-orange-400">注意力</span>,
						<span class="text-orange-400">就是</span>
					</p>
					<p class="fragment fade-up text-left pl-10">
						Output：
						<br />
						<span class="text-orange-400">注意力</span>,
						<span class="text-orange-400">就是</span>,
						<strong><u class="text-blue-300">你</u></strong><sup class="text-yellow-400">NEW!</sup>
					</p>
				</section>

				<section>
					<p class="text-left pl-10">
						Input：
						<br /><span class="text-pink-500">&lt;START&gt;</span>,
						<span class="text-green-400">Attention</span>,
						<span class="text-green-400">is</span>,
						<span class="text-green-400">all</span>,
						<span class="text-green-400">you</span>,
						<span class="text-green-400">need</span>,
						<span class="text-pink-500">&lt;END&gt;</span>
					</p>
					<p class="text-left pl-10">
						Target：
						<br />
						<span class="text-pink-500">&lt;START&gt;</span>,
						<span class="text-orange-400">注意力</span>,
						<span class="text-orange-400">就是</span>,
						<span class="text-orange-400">你</span>
					</p>
					<p class="fragment fade-up text-left pl-10">
						Output：
						<br />
						<span class="text-orange-400">注意力</span>,
						<span class="text-orange-400">就是</span>,
						<span class="text-orange-400">你</span>,
						<strong><u class="text-blue-300">所</u></strong><sup class="text-yellow-400">NEW!</sup>
					</p>
				</section>

				<section>
					<p class="text-left pl-10">
						Input：
						<br /><span class="text-pink-500">&lt;START&gt;</span>,
						<span class="text-green-400">Attention</span>,
						<span class="text-green-400">is</span>,
						<span class="text-green-400">all</span>,
						<span class="text-green-400">you</span>,
						<span class="text-green-400">need</span>,
						<span class="text-pink-500">&lt;END&gt;</span>
					</p>
					<p class="text-left pl-10">
						Target：
						<br />
						<span class="text-pink-500">&lt;START&gt;</span>,
						<span class="text-orange-400">注意力</span>,
						<span class="text-orange-400">就是</span>,
						<span class="text-orange-400">你</span>,
						<span class="text-orange-400">所</span>
					</p>
					<p class="fragment fade-up text-left pl-10">
						Output：
						<br />
						<span class="text-orange-400">注意力</span>,
						<span class="text-orange-400">就是</span>,
						<span class="text-orange-400">你</span>,
						<span class="text-orange-400">所</span>,
						<strong><u class="text-blue-300">需要</u></strong><sup class="text-yellow-400">NEW!</sup>
					</p>
				</section>

				<section>
					<p class="text-left pl-10">
						Input：
						<br /><span class="text-pink-500">&lt;START&gt;</span>,
						<span class="text-green-400">Attention</span>,
						<span class="text-green-400">is</span>,
						<span class="text-green-400">all</span>,
						<span class="text-green-400">you</span>,
						<span class="text-green-400">need</span>,
						<span class="text-pink-500">&lt;END&gt;</span>
					</p>
					<p class="text-left pl-10">
						Target：
						<br />
						<span class="text-pink-500">&lt;START&gt;</span>,
						<span class="text-orange-400">注意力</span>,
						<span class="text-orange-400">就是</span>,
						<span class="text-orange-400">你</span>,
						<span class="text-orange-400">所</span>,
						<span class="text-orange-400">需要</span>
					</p>
					<p class="fragment fade-up text-left pl-10">
						Output：
						<br />
						<span class="text-orange-400">注意力</span>,
						<span class="text-orange-400">就是</span>,
						<span class="text-orange-400">你</span>,
						<span class="text-orange-400">所</span>,
						<span class="text-orange-400">需要</span>,
						<strong><u class="text-blue-300">的</u></strong><sup class="text-yellow-400">NEW!</sup>
					</p>
				</section>

				<section>
					<p class="text-left pl-10">
						Input：
						<br /><span class="text-pink-500">&lt;START&gt;</span>,
						<span class="text-green-400">Attention</span>,
						<span class="text-green-400">is</span>,
						<span class="text-green-400">all</span>,
						<span class="text-green-400">you</span>,
						<span class="text-green-400">need</span>,
						<span class="text-pink-500">&lt;END&gt;</span>
					</p>
					<p class="text-left pl-10">
						Target：
						<br />
						<span class="text-pink-500">&lt;START&gt;</span>,
						<span class="text-orange-400">注意力</span>,
						<span class="text-orange-400">就是</span>,
						<span class="text-orange-400">你</span>,
						<span class="text-orange-400">所</span>,
						<span class="text-orange-400">需要</span>,
						<span class="text-orange-400">的</span>
					</p>
					<p class="fragment fade-up text-left pl-10">
						Output：
						<br />
						<span class="text-orange-400">注意力</span>,
						<span class="text-orange-400">就是</span>,
						<span class="text-orange-400">你</span>,
						<span class="text-orange-400">所</span>,
						<span class="text-orange-400">需要</span>,
						<span class="text-orange-400">的</span>,
						<strong><u class="text-pink-500">&lt;END&gt;</u></strong><sup class="text-yellow-400">結束！</sup>
					</p>
				</section>

			</section>

			<!-- Multi-Head Attention -->
			<section>
				<section>
					<p style="font-size: 150%;">
						Multi-Head Attention
					</p>
					<p class="fragment fade-up">
						NLP 界的 V8 引擎
					</p>
				</section>
				<section>
					<p class="text-left pl-10">
						在開始<del> 解剖 </del>解析 Transformer 前，
					</p>
					<p class="text-left pl-10">
						先來了解一下這個新架構的獨特之處
					</p>
					<p class="fragment fade-up">
						「Multi-Head Attention」
					</p>
				</section>
				<section>
					<p class="text-left pl-10 text-4xl">
						Multi-Head Attention 正如其名，<br /> 由數個 Head 合成
					</p>
					<p class="fragment fade-up text-left pl-10 text-4xl">
						而每個 Head 具有自己的關注標準，這使得 Multi-Head Attention 可以在詞字之間獲得更豐富的語意關係
					</p>
				</section>
				<section>
					<p class="text-left pl-10">
						\[ MultiHeadAttention(Q_{input},K_{input},V_{input})\\ = Concat(Head_1,Head_2,...,Head_h)W^{O}
						\]
					</p>
					<p>
						其中 <span class="text-yellow-400">\(Q_{input},K_{input},V_{input}\)</span> 是 Embedding 序列
					</p>
					<p class="fragment fade-up text-right pr-32 pt-10">
						\(\definecolor{yello400}{RGB}{246, 224, 94}\)
						\(V_{input},K_{input}\in\mathbb{R}^{{\color{yello400}Sequence_K} \times d_{embedding}}\)
						\(Q_{input}\in\mathbb{R}^{{\color{yello400}Sequence_Q} \times d_{embedding}}\)
					</p>
				</section>
				<section>
					<p class="text-left pl-10 text-4xl">
						\(V_{input}\) 與 \(K_{input}\) 來自相同語句，\(Q_{input}\) 則不一定
					</p>
					<img src="./img/k_input-v_input-q_input.png">
				</section>
				<section>
					<p class="text-left pl-10">
						Embedding 序列在通過線性轉換後就會變成 \(Q,K,V\) 矩陣
					</p>
					<p class="fragment fade-up text-left pl-10">
						\[ \definecolor{pink500}{RGB}{237,100,166} \definecolor{indigo400}{RGB}{127, 156, 245}
						\definecolor{blue400}{RGB}{99, 179, 237}
						Q_{i}=Q_{input}W_{i}^Q,W^Q\in\mathbb{R}^{{\color{indigo400}d_{embedding}}\times
						{\color{blue400}d_k}}\\
						K_{i}=K_{input}W_{i}^K,W^K\in\mathbb{R}^{{\color{indigo400}d_{embedding}}\times
						{\color{blue400}d_k}}\\
						V_{i}=V_{input}W_{i}^V,W^V\in\mathbb{R}^{{\color{indigo400}d_{embedding}}\times
						{\color{pink500}d_v}} \]
					</p>
				</section>
				<section>
					<p>
						而 \(Head_i\) 就是由 \(Q_{i},K_{i},V_{i}\) 通過<br /> Scaled Dot Product Attention 計算後的答案
					</p>
					<p>
						\(Head_i = Softmax(\frac{Q_iK_i^T}{\sqrt{d_k}})V_i\)<br />
					</p>
				</section>
				<section>
					<p>
						\(Head_i = Softmax(\frac{Q_iK_i^T}{\sqrt{d_k}})V_i\)
					</p>
					<p class="text-left pl-10 text-4xl">
						讓 \(Q(query)\) 與 \(K(key)\) 執行點積與 \(Softmax\)，藉此得出其中每個 token 的匹配度(關注權重)
					</p>
					<p class="fragment fade-up text-left pl-10 text-4xl">
						補充：匹配度可以使用不同的計算方式，只是 Transformer 是利用點積計算
					</p>
				</section>
				<section>
					<p>
						\(Head_i = Softmax(\frac{Q_iK_i^T}{\sqrt{d_k}})V_i\)
					</p>
					<p class="text-left pl-10 text-4xl">
						再利用關注權重與 \(V(value)\) 計算加權平均以獲得 Scaled Dot Product Attention 的輸出
					</p>
				</section>
				<section>
					<p class="text-left pl-10">
						為了滿足計算條件，\(Q,K,V\) 的 Shape 要求如下
					</p>
					<ul>
						<li>
							\(Q\)：<span class="text-orange-400">\(length_Q\)</span> \(\times\) <span
								class="text-blue-400">\(d_k\)</span>
						</li>
						<li>
							\(K\)：<span class="text-teal-400">\(length_K\)</span> \(\times\) <span
								class="text-blue-400">\(d_k\)</span>
						</li>
						<li>
							\(V\)：<span class="text-teal-400">\(length_K\)</span> \(\times\) <span
								class="text-pink-500">\(d_v\)</span>
						</li>
					</ul>
					<p class="fragment fade-up">
						Head：<span class="text-orange-400">\(length_Q\)</span> \(\times\) <span
							class="text-pink-500">\(d_v\)</span>
					</p>
				</section>
				<section>
					<p class="text-4xl">
						\[ MultiHeadAttention(Q_{input},K_{input},V_{input})\\ = Concat(Head_1,Head_2,...,Head_h)W^{O}
						\]
					</p>
					<p class="text-left pl-10 text-4xl">
						將上面計算得到的數個 Head 串聯之後進行線性變換<br /> 即為 Multi Head Attention
					</p>
					<p class="">
						\(\definecolor{pink500}{RGB}{237,100,166}\) \(\definecolor{indigo400}{RGB}{127, 156, 245}\)
						\(W^O\in \mathbb{R}^{(h\times {\color{pink500}d_{v}})\times {\color{indigo400}d_{embedding}}}\)
					</p>
				</section>
				<section>
					<p class="text-red-600 text-6xl">
						前方高能
					</p>
					<p class="fragment fade-up text-red-600 text-6xl">
						前方高能
					</p>
					<p class="fragment fade-up text-red-600 text-6xl">
						前方高能
					</p>
				</section>
				<section>
					<p>
						讓我們從向量空間的觀點來理解前面到底做了什麼
					</p>
				</section>
				<section>
					<p class="text-left pl-32">
						首先，\(Q_{input}\) 與 \(K=V_{input}\)<br />
						分別來自於兩個不同的向量空間
					</p>
				</section>
				<section>
					<img src="./img/QKV/0.png" />
				</section>
				<section>
					<p class="text-left pl-10">
						我們希望能找出一種映射方式，使得 \(Q_{input}\) 能映射到 \(K=V_{input}\) 所處的向量空間，變成 \(Q'_{input}\)
					</p>
				</section>
				<section>
					<img src="./img/QKV/1.png" />
				</section>
				<section>
					<p class="text-left pl-10">
						且這個映射必須依靠 \(K=V_{input}\) 中的向量作為 basis 來達成，這樣就能使 \(Q'_{input}\) 帶有 \(K=V_{input}\) 向量的資訊
					</p>
				</section>
				<section>
					<img src="./img/QKV/2.png" />
				</section>
				<section>
					<p class="text-left pl-10">
						然而，我們還是不知道要如何將 \(Q_{input}\) 映射至 \(K=V_{input}\)
					</p>
					<p class="fragment fade-up text-left pl-10">
						為此，先將 \(Q_{input}\) 與 \(K=V_{input}\) 另外線性轉換到兩個向量空間
					</p>
				</section>
				<section>
					<p class="text-left pl-10">
						\(K=V_{input}\) 執行兩種線性轉換後變成<br />
						<span class="text-pink-500">Keys</span> & <span class="text-green-400">Values</span>，分別處在 <span
							class="text-pink-500">QK Space</span> 與 <span class="text-green-400">V
							Space</span>
					</p>
					<p class="fragment fade-up text-left pl-10">
						而 \(Q_{input}\) 執行線性轉換後則變成位在 <span class="text-pink-500">QK Space</span> 的 <span
							class="text-pink-500">Querys</span>
					</p>
				</section>
				<section>
					<img src="./img/QKV/3.png" class="w-4/5 m-auto inline-block" />
				</section>
				<section>
					<p class="text-left pl-10">
						<span class="text-pink-500">Keys</span> & <span class="text-green-400">Values</span>
						是源於同個向量做不同轉換的結果，因此可以互相對應
					</p>
				</section>
				<section>
					<img src="./img/QKV/4.png" />
				</section>
				<section>
					<p class="text-left pl-10">
						接下來就可以分析位在同個空間中的 Querys 與 Keys
					</p>
				</section>
				<section>
					<img src="./img/QKV/5.png" />
					<p class="">
						計算 Query 與 Keys 的匹配度
					</p>
				</section>
				<section>
					<img src="./img/QKV/6.png" class="m-auto inline-block" />
					<p class="text-left text-3xl">
						藉由匹配度以及對應的 Values，便可以在 V Space 找出對應的 query'
					</p>
				</section>
				<section>
					<p class="text-left pl-10">
						最後只需要將 query' 從 V Space 線性轉換回 \(K=V_{input}\) Space，
						就可得到 \(Q_{input}\) 映射到 \(K=V_{input}\) Space 的 \(Q'_{input}\)
					</p>
				</section>
				<section>
					<img src="./img/QKV/7.png" class="w-4/5 m-auto inline-block" />
				</section>
				<section>
					<p class="text-left pl-10">
						但是，只由一個 V Space 映射回去的位置並不準確
					</p>
					<p class="text-left pl-10">
						為此才使用多個 QK、V Space
					</p>
				</section>
				<section>
					<img src="./img/QKV/8.png" class="w-4/5 m-auto inline-block" />
				</section>
				<section>
					<p class="text-left pl-10">
						這樣使用多個 V Space 映射回去便可得出比單一映射更加精準的結果
					</p>
				</section>
				<section>
					<img src="./img/QKV/9.png" class="w-4/5 m-auto inline-block" />
				</section>
			</section>

			<!-- 認真拆解 Transformer -->
			<section>
				<section>
					<p style="font-size: 150%;">
						認真拆解 Transformer
					</p>
					<ol>
						<li><a href="#/5/3">Position Encoding</a></li>
						<li><a href="#/5/11">Encoder Layer</a></li>
						<li><a href="#/5/23">Decoder Layer</a></li>
					</ol>
				</section>
				<section>
					<img src="./img/transformer.png" class="w-2/3 m-auto inline-block" />
					<br /> Transformer
				</section>
				<section>
					<img src="./img/transformer-embedding.png" class="w-2/3 m-auto inline-block" />
					<br /> Embedding 就是前面科普過的 <a href="index.html#/2/6">Word Embedding</a>
				</section>
				<section>
					<img src="./img/transformer-positional-encoding.png" class="w-2/3 m-auto inline-block" />
					<br /> Positional Encoding
				</section>
				<section>
					<p class="text-left pl-10">
						由於 Transformer 僅使用了注意力機制，<br /> 所以不像 CNN 與 RNN 具備捕捉位置關係的能力
					</p>
					<p class="fragment fade-up text-left pl-10">
						但在語言模型中，詞字的序列關係至關重要
					</p>
				</section>
				<section>
					<p class="text-left pl-10">
						因此研究團隊提出了一種位置標記方法，<br /> 直接將位置資訊寫進輸入中
					</p>
					<p class="text-left pl-10">
						\(\definecolor{yello400}{RGB}{246, 224, 94}\)
						\(PE_{({\color{yello400}pos},{\color{yello400}2i})}=sin({\color{yello400}pos}/10000^{{\color{yello400}2i}/d_{embedding}})\)
						\(PE_{({\color{yello400}pos},{\color{yello400}2i+1})}=cos({\color{yello400}pos}/10000^{({\color{yello400}2i+1})/d_{embedding}})\)
					</p>
					<p class="text-left pl-10">
						\(PE_{out}=PE_{in}+PE\)
					</p>
				</section>
				<section>
					<p class="text-left pl-10">
						\(\definecolor{yello400}{RGB}{246, 224, 94}\)
						\(PE_{({\color{yello400}pos},{\color{yello400}2i})}=sin({\color{yello400}pos}/10000^{{\color{yello400}2i}/d_{embedding}})\)
						\(PE_{({\color{yello400}pos},{\color{yello400}2i+1})}=cos({\color{yello400}pos}/10000^{{\color{yello400}2i}/d_{embedding}})\)
					</p>
					<p>
					<ul>
						<li>pos：<span class="text-yellow-400">第 pos 個</span> Embedding 序列</li>
						<li>i：Embedding 向量的<span class="text-yellow-400">第 i 個維度</span>，當 i 是<span
								class="text-pink-400">偶數</span>時用 sin 編碼，<span class="text-pink-400">奇數</span>時則用 cos 編碼
						</li>
					</ul>
					</p>
				</section>
				<section>
					<img src="./img/positional-encoding.png" class="w-2/3 m-auto inline-block" />
					<p class="text-left pl-10 text-4xl">Sequence length = 50、Embedding depth = 10 的 positional encoding
					</p>
				</section>
				<section>
					<img src="./img/transformer-encoders-decoders.png" class="w-2/3 m-auto inline-block" />
				</section>
				<section>
					<img src="./img/encoders-decoders.png" class="w-2/3 m-auto inline-block" />
				</section>
				<section>
					<img src="./img/encoders.png" class="w-2/3 m-auto inline-block" />
				</section>
				<section>
					<img src="./img/encoder-layer.png" class="w-2/3 m-auto inline-block" />
				</section>
				<section>
					<img src="./img/encoder-layer-multi-head-attention.png" class="w-2/3 m-auto inline-block" />
				</section>
				<section>
					<img src="./img/multi-head-attention.png" class="w-2/3 m-auto inline-block" />
				</section>
				<section>
					<img src="./img/attention-pre-linear.png" />
				</section>
				<section>
					<img src="./img/encoder-attention-0.png" />
				</section>
				<section>
					<img src="./img/encoder-attention-1.png" />
				</section>
				<section>
					<img src="./img/encoder-attention-2.png" />
				</section>
				<section>
					<img src="./img/encoder-attention-3.png" />
				</section>
				<section>
					<img class="w-2/3 m-auto inline-block" src="./img/residual.png" />
					<p class="text-left pl-10 text-3xl">
						藉由 residual 結構保留 positional encoding 的資訊，<br />
						因此不需要每通過一次 encoder/decoder 就重加一次位置訊息
					</p>
				</section>
				<section>
					小科普：Layer Normalization
					<p class="text-left pl-10 text-3xl">
						你可以簡單地將其當成 Channel 版的 Batch Normalization，<br />
						他運算的對象由 Batch Axis 換成了 Channel Axis<br />
						<br />
						(註：在 Transformer 裡就是對 Embedding Vector 執行)
					</p>
				</section>
				<section>
					<p class="text-left pl-10 text-4xl">
						優勢在於訓練與實際使用都有效果，且獨立於 Batch，<br />
						使得每筆資料的輸入大小(長度)可不一致
					</p>
					<p class="text-left pl-10 text-4xl">
						但在 Batch Size 較大的時候還是拚不過 Batch Normalization
					</p>
				</section>
				<section>
					<img src="./img/decoders.png" class="w-2/3 m-auto inline-block" />
				</section>
				<section>
					<img src="./img/decoder-layer.png" class="w-2/3 m-auto inline-block" />
				</section>
				<section>
					<img src="./img/decoder-layer-masked-multi-head-attention.png" class="w-2/3 m-auto inline-block" />
				</section>
				<section>
					<img src="./img/decoder-masked-attention-0.png" />
				</section>
				<section>
					<img class="m-auto inline-block" src="./img/decoder-masked-attention-1.png" />
					<p class="text-3xl">
						加上負很大的值後通過 Softmax，便可讓要 masked 的位置近似 0
					</p>
				</section>
				<section>
					<img src="./img/decoder-layer-multi-head-attention.png" class="w-2/3 m-auto inline-block" />
				</section>
				<section>
					<img src="./img/decoder-attention-0.png" />
				</section>
				<section>
					<img src="./img/decoder-attention-1.png" />
				</section>
				<section>
					<img src="./img/decoder-attention-2.png" />
				</section>
				<section>
					<img src="./img/decoder-attention-3.png" />
				</section>
				<section>
					<img src="./img/transformer-linear-softmax.png" class="w-2/3 m-auto inline-block" />
					<p>
						執行最後一層後輸出預測的單詞機率分布
					</p>
				</section>
			</section>

			<!-- 實驗結果 & 結論 -->
			<section>
				<section>
					<p style="font-size: 150%;">
						實驗 & 結論
					</p>
				</section>
				<section>
					<p class="text-left pl-10">
						訓練硬體：
					</p>
					<p class="text-left pl-20 text-4xl">8 顆 NVIDIA P100 GPUs</p>
					<p class="text-left pl-10">
						訓練資料集：
					</p>
					<p class="text-left pl-20 text-3xl">WMT(Workshop on Statistical Machine Translation) 2014
						的「英文轉德文」(EN-DE)
						與「英文轉法文」(EN-FR)</p>
				</section>
				<section>
					<p class="text-left pl-10">
						訓練耗時：
					<ul>
						<li>
							base model
							<p class="text-3xl">
								100,000 steps(12 hours)，每個 step 花費 0.4 秒
							</p>
						</li>
						<li>
							big model
							<p class="text-3xl">
								300,000 steps(3.5 days)，每個 step 花費 1.0 秒
							</p>
						</li>
					</ul>
				</section>
				<section>
					<p class="text-left pl-32">
						Regularization：
					</p>
					<ul>
						<li>
							Dropout
						</li>
						<li>
							Label Smoothing
						</li>
					</ul>
				</section>
				<section>
					<p class="text-left pl-10">
						Dropout
					</p>
					<ul class="text-3xl">
						<li class="pt-5">
							在 Input 與 Target 執行完<br />
							Positional Encoding 後會執行 Dropout
						</li>
						<li class="pt-5">
							Encoder & Decoder 中，<br />
							每次執行完 (Masked)Multi-Head Attention<br />
							或 Feed Forward 後都會接 Dropout
						</li>
					</ul>

				</section>
				<section>
					<p class="text-left pl-10">
						Label Smoothing
					</p>
					<p class="text-left pl-32 text-3xl">
						為 Ground Truth 的 One Hot Encoding<br />
						加上機率雜訊 <span class="text-4xl">\(\epsilon_{ls}\)</span>，<br />
						可以避免因訓練集不足以代表所有樣本特徵而造成的 Overfitting

					</p>
				</section>
				<section>
					<img src="./img/label-smoothing.png">
					Label Smoothing
				</section>

				<section>
					<p class="text-left pl-48">
						Optimizer：Adam
					</p>
					<ul>
						<li>\(\beta_1=0.9\)</li>
						<li>\(\beta_2=0.98\)</li>
						<li>\(\epsilon=10^{-9}\)</li>
					</ul>
				</section>
				<section>
					<p class="text-left text-6xl">
						\(lrate=\frac{min(\frac{1}{\sqrt{step\_num}},\frac{step\_num}{warmup\_steps^{1.5}})}{\sqrt{d_{embedding}}}\)
					</p>
					<p class="text-left">
						\(warmup\_steps=4000\)
					</p>
				</section>
				<section>
					<img src="./img/experiment-base.png" />
					<table class="text-2xl">
						<tr>
							<th>\(N\)</th>
							<td>encoder&decoder 的數量</td>
						</tr>
						<tr>
							<th>\(d_{model}\)</th>
							<td>embedding length (前面的 \(d_{embedding}\))</td>
						</tr>
						<tr>
							<th>\(d_{ff}\)</th>
							<td>encoder&decoder 中，Feed Forward 隱藏層神經元數量</td>
						</tr>
						<tr>
							<th>\(h\)</th>
							<td>Multi-Head Attention 的 head 個數</td>
						</tr>
						<tr>
							<th>\(d_{k}\)</th>
							<td>\(Q_{input}、K_{input}\) 經過線性轉換得到之 \(Q、K\) 的深度(維度)</td>
						</tr>
						<tr>
							<th>\(d_{v}\)</th>
							<td>\(V_{input}\) 經過線性轉換得到之 \(V\) 的深度(維度)</td>
						</tr>
						<tr>
							<th>\(P_{drop}\)</th>
							<td>Dropout 設定的機率</td>
						</tr>
						<tr>
							<th class="text-3xl">\(\epsilon_{ls}\)</th>
							<td>label smoothing 中的機率雜訊</td>
						</tr>
					</table>
				</section>
				<section>
					<img src="./img/experiment-a.png">
					<p class="text-left pl-10 text-3xl">
						實驗(A)主要在測試 head 數量對正確率的影響。<br />
						從結果可以發現，在不過度壓縮 d<sub>k</sub> 與 d<sub>v</sub> 的狀況下，<br />
						有較多 head 的模型正確率更高。
					</p>
				</section>
				<section>
					<img src="./img/experiment-b.png">
					<p class="text-3xl">
						由實驗(B)可知過度壓縮 d<sub>k</sub> 會使正確率下降。
					</p>
				</section>
				<section>
					<img src="./img/experiment-c.png">
					<p class="text-left pl-10 text-3xl">
						實驗(C)在測試參數量對模型的影響，結論是「大力出奇蹟」
					</p>
				</section>
				<section>
					<img src="./img/experiment-d.png">
					<p class="text-left pl-10 text-3xl">
						實驗(D)測試得出使用 Dropout 可有效避免 Overfitting
					</p>
				</section>
				<section>
					<img src="./img/experiment-e.png">
					<p class="text-left pl-10 text-3xl">
						實驗(E)使用了 <a href="https://arxiv.org/abs/1705.03122">Convolutional Sequence to Sequence
							Learning</a> 所提出的 Positional Embedding 替代 Positional Encoding，實驗結果差別不大。
					</p>
				</section>
				<section>
					<img src="./img/experiment-big.png">
					<p class="text-6xl">
						大力出奇蹟
					</p>
				</section>
				<section>
					<img src="./img/experiment-all.png">
					<p class="text-3xl">
						總覽
					</p>
				</section>
				<section>
					<img src="./img/newstest2014.png">
					在 newstest2014 資料集與其他模型的比較結果
				</section>
				<section>
					<p class="text-left pl-10">
						Transformer 在剛推出時，<br />
						光是 Training Cost 低的 Base Model 在<br />
						「英文轉德文」上的表現就已經輾壓眾生。
					</p>
					<p class="text-left pl-10">
						Big Model 更是在兩項任務都超過當時的 SOTA
					</p>
				</section>
			</section>

			<section>
				<section>
					<p style="font-size: 150%;">
						參考資料
					</p>
				</section>
				<section>
					<p class="text-4xl text-left">
						[1]<a href="https://projector.tensorflow.org/">Embedding Projector</a>
					</p>
					<p class="text-3xl text-left px-24">
						由 Google 發布的互動式高維資料視覺化網頁工具，可以方便使用者查看各個單詞向量之間的相似關係。
					</p>
				</section>
				<section>
					<p class="text-4xl text-left">
						[2]<a href="https://www.tensorflow.org/tutorials/text/transformer">Transformer model for
							language understanding</a>
					</p>
					<p class="text-3xl text-left px-24">
						Google 放在 Tensorflow 官網的教學，<br />
						有放在 Colab 上面，<br />
						配合 TF2 寫成的程式碼讓人非常容易理解，<br />
						對 Transformer 有興趣的人請務必去看。
					</p>
				</section>
				<section>
					<p class="text-4xl text-left">
						[3]<a
							href="https://leemeng.tw/neural-machine-translation-with-transformer-and-tensorflow2.html">淺談神經機器翻譯
							& 用 Transformer 與 TensorFlow 2 英翻中</a>
					</p>
					<p class="text-4xl text-left">
						[4]<a href="https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html">進擊的 BERT：NLP
							界的巨人之力與遷移學習</a>
					</p>
					<p class="text-4xl text-left">
						[5]<a href="https://leemeng.tw/gpt2-language-model-generate-chinese-jing-yong-novels.html">直觀理解
							GPT-2 語言模型並生成金庸武俠小說</a>
					</p>
				</section>
			</section>

			<section>
				<section>
					<p style="font-size: 150%;">
						聊聊
					</p>
				</section>
				<section>
					<img src="./img/elmo.jpg" class="w-1/3 m-auto inline-block" />
				</section>
				<section>
					<img src="./img/elmo-bert.jpg" class="w-1/2 m-auto inline-block" />
				</section>
				<section>
					<img src="./img/elmo-bert-gpt2.jpg" class="m-auto inline-block" />
				</section>
				<section>
					<img src="./img/gpt3.png" class="w-1/2 m-auto inline-block" />
				</section>
				<section>
					GPT-3 的參數量：1,750億 (175G)<br />
					如果一個參數是 4 byte，<br />
					GPT-3 大概是 700 GB<br />
				</section>
				<section>
					<img src="./img/gpt3-meme.jpg" class="w-1/2 m-auto inline-block" />
				</section>
			</section>
			<section id="transitions">
				<h2>Transition Styles</h2>
				<p>
					You can select from different transitions, like: <br>
					<a href="?transition=none#/transitions">None</a> -
					<a href="?transition=fade#/transitions">Fade</a> -
					<a href="?transition=slide#/transitions">Slide</a> -
					<a href="?transition=convex#/transitions">Convex</a> -
					<a href="?transition=concave#/transitions">Concave</a> -
					<a href="?transition=zoom#/transitions">Zoom</a>
				</p>
			</section>

			<section id="themes">
				<h2>Themes</h2>
				<p>
					reveal.js comes with a few themes built in: <br>
					<!-- Hacks to swap themes after the page has loaded. Not flexible and only intended for the reveal.js demo deck. -->
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/black.css'); return false;">Black
						(default)</a> -
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/white.css'); return false;">White</a>
					-
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/league.css'); return false;">League</a>
					-
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/sky.css'); return false;">Sky</a>
					-
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/beige.css'); return false;">Beige</a>
					-
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/simple.css'); return false;">Simple</a>
					<br>
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/serif.css'); return false;">Serif</a>
					-
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/blood.css'); return false;">Blood</a>
					-
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/night.css'); return false;">Night</a>
					-
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/moon.css'); return false;">Moon</a>
					-
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/solarized.css'); return false;">Solarized</a>
				</p>
			</section>
		</div>

	</div>

	<script src="js/reveal.js"></script>

	<script>
		// More info https://github.com/hakimel/reveal.js#configuration
		Reveal.initialize({
			controls: true,
			progress: true,
			center: true,
			hash: true,
			slideNumber: true,
			transition: 'slide', // none/fade/slide/convex/concave/zoom

			// More info https://github.com/hakimel/reveal.js#dependencies
			dependencies: [{
				src: 'plugin/markdown/marked.js',
				condition: function () {
					return !!document.querySelector('[data-markdown]');
				}
			}, {
				src: 'plugin/markdown/markdown.js',
				condition: function () {
					return !!document.querySelector('[data-markdown]');
				}
			}, {
				src: 'plugin/highlight/highlight.js',
				async: true
			}, {
				src: 'plugin/search/search.js',
				async: true
			}, {
				src: 'plugin/zoom-js/zoom.js',
				async: true
			}, {
				src: 'plugin/notes/notes.js',
				async: true
			}]
		});
	</script>

</body>

</html>