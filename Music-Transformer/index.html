<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Music Transformer報告</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0">

		<link rel="stylesheet" href="css/reset.css">
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css" id="theme">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/monokai.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement('link');
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName('head')[0].appendChild(link);
		</script>
		<script type="text/javascript"
			src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
			</script>

		<style>
			@font-face {
				font-family: custom-serif;
				src: local(Microsoft JhengHei), local("DFKai-sb");
				unicode-range: U+4E00-9FFF;
			}

			@font-face {
				font-family: custom-serif;
				src: local(Source Code Pro), local(Arial);
				unicode-range: U+00-024F;
			}

			section {
				font-family: custom-serif;
			}
		</style>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<p style="font-size: 120%;">
						<a href="https://arxiv.org/abs/1809.04281">Music Transformer</a>
					</p>
					<br>
					<p style="font-size: 70%;text-align:left;position: relative;left:10%;">
						<nobr>Cheng-Zhi Anna Huang∗</nobr>,
						<nobr>Ashish Vaswani</nobr>,
						<nobr>Jakob Uszkoreit</nobr>,
						<nobr>Noam Shazeer</nobr>,
						<nobr>Ian Simon</nobr>,
						<nobr>Curtis Hawthorne</nobr>,
						<nobr>Andrew M. Dai</nobr>,
						<nobr>Matthew D. Hoffman</nobr>,
						<nobr>Monica Dinculescu</nobr>,
						<nobr>Douglas Eck</nobr>
					</p>
					<p style="font-size: 70%;text-align:left;position: relative;left:10%;">
						<nobr>Google Brain</nobr>
					</p>
				</section>

				<section>
					<h3>目錄</h3>
					<ol>
						<li>
							<p>
								<nobr>介紹</nobr>
							</p>
						</li>
						<li>
							<p>
								<nobr>貢獻</nobr>
							</p>
						</li>
						<li>
							<p>
								<nobr>模型架構</nobr>
							</p>
						</li>
						<li>
							<p>
								<nobr>實驗結果&結論</nobr>
							</p>
						</li>
						<li>
							<p>
								<nobr>心得</nobr>
							</p>
						</li>
						<li>
							<p>
								<nobr>參考資料</nobr>
							</p>
						</li>
					</ol>

				</section>

				<section>
					<section>
						<h3>介紹</h3>
					</section>

					<section>
						<p style="text-align:left;">
							在一段樂曲中
							<br>
							音樂大多都是由同樣的結構、特徵組合而成
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							這些特徵會在多個時間點重複
							<br>
							重複的部分可能會是<strong style="color: #ff5555;">樂想(音樂動機，motifs)</strong>、
							<br>
							<strong style="color: #ff5555;">樂句(phrase)</strong>或是<strong
								style="color: #ff5555;">某段音樂</strong>
						</p>
					</section>

					<section>
						<p style="text-align:left;">
							而在處理這種前後相關的序列問題上
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							由注意力機制構成的
							<br>
							<a href="https://arxiv.org/abs/1706.03762">Transformer</a>(由Vaswani等人在2017年提出)
							<br>
							就具有良好的表現
						</p>
					</section>

					<section>
						<p style="text-align:left;">
							Transformer在較長的時間尺度依然能保留前後文的關係
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							這表示Transformer可能也適合用於音樂生成上
						</p>
					</section>

					<section>
						<p>
							在音樂創作和表演中，前後的<strong style="color: #ff5555;">相對關係</strong>非常重要
						</p>
						<p class="fragment fade-up">
							但是
							<br>
							<nobr style="text-align:left;">在原始的Transformer中前後文是以絕對位置紀錄關係</nobr>
						</p>
					</section>
					<section>
						<p style="text-align:left;">
							Shaw等人在2018年曾發表過一篇
							<br>
							<a href="https://arxiv.org/abs/1803.02155">處理Transformer中相對位置關係</a>的論文
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							<nobr>但並不適合用在像音樂生成這樣序列較長的問題上</nobr>
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							因為這方法的記憶體複雜度是<strong style="color: #ff5555;">O(L<sup>2</sup>D)</strong>
							<br>
							<nobr class="fragment fade-up">L是序列長度，D是模型隱藏狀態的維度</nobr>
						</p>
					</section>
					<section>
						<p style="text-align:left;">
							因此，本論文提出了一種算法
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							讓記憶體複雜度變成<strong style="color: #ff5555;">O(LD)</strong>
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							<nobr>
								這使本論文能夠生成數分鐘長音樂結構<br>
								(數千拍，這是<a href="https://arxiv.org/abs/1808.03715">Oore等人在2018年提出的算法</a>的4倍長)
							</nobr>
						</p>
					</section>
					<section>
						<p style="text-align:left;">
							用此模型能生成具有連續性並契合樂想的音樂
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							使用的資料集是
							<br>
							<nobr>JSB Chorales和Piano-e-Competition</nobr>
						</p>
					</section>
					<section>
						<p style="text-align:left;">
							關於Piano-e-Competition的資料集
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							由參賽者表演記錄的MIDI組成
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							幀率小於10毫秒
						</p>
					</section>
					<section>
						<p style="text-align:left;">
							而且為了不必要的空間浪費
							<br>
							(不是每個時間點都有聲音事件)
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							本論文使用一種類似MIDI並基於事件的稀疏儲存方式(<a href="https://arxiv.org/abs/1808.03715">Oore等人，2018</a>)
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							使一分鐘長、幀率10毫秒的音樂只需以<strong style="color: #ff5555">2k</strong>左右的序列長度表示，而不需到固定的6k~8k
						</p>
					</section>
				</section>

				<section>
					<section>
						<h3>貢獻</h3>
					</section>

					<section>
						<p style="text-align:left;">
							本論文是第一個使用Transformer生成時間長達1分鐘的音樂研究成果
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							在此之前是Oore等人使用LSTMs的音樂生成算法
							<br>
							但長度只有到15秒
						</p>
					</section>
					<section>
						<p style="text-align:left;">
							而在音樂品質的部分
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							<nobr>使用相對注意力機制的Music Transformer能產生</nobr>
							<br>
							比原始Transform更加連貫的音樂
						</p>
					</section>
					<section>
						<p style="text-align:left;">
							此外
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							在seq2seq設置中<br>
							Transformer可以生成伴奏用的旋律
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							讓使用者能跟模型互動
						</p>
					</section>
					<section>
						<p style="text-align:left;">
							在演算法方面
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							經過改進的相對注意力機制大幅的減少記憶體消耗
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							像是對L = 2048、D = 512的序列，每層的記憶體使用量就從8.5GB減少到4.2MB
						</p>
					</section>
				</section>

				<section>
					<section>
						<h3>模型架構</h3>
					</section>

					<section>
						<h4>資料格式</h4>
					</section>

					<section>
						<p style="text-align:left;">
							為了採用語言建模的方式來訓練音樂生成模型
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							因此將音樂轉成離散序列表示
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							其中，「詞彙」是由資料集決定的
						</p>
					</section>

					<section>
						<p style="text-align:left;">
							不同的數據集用不同方法將和絃音樂轉成單一串流的離散音樂序列
						</p>
					</section>

					<section>
						<p style="text-align:left;">
							例如，JSB Chorale是由四部合唱組成的
							<br>
							音樂資料集
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							他的資料就是以矩陣表示
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							矩陣的<strong style="color: aqua">行</strong>對應<strong style="color: aqua">聲音</strong>，而<strong
								style="color: aqua">列</strong>則對應<strong style="color: aqua">離散化為16分音符的時間</strong>
						</p>
					</section>

					<section>
						<p style="text-align:left;">
							JSB Chorale矩陣中的元素則表示演奏的<strong style="color: #ff5555">音高</strong>
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							而要如何將矩陣序列化呢?
						</p>
					</section>

					<section>
						<p style="text-align:left;">
							JSB Chorale矩陣中的元素則表示演奏的<strong style="color: #ff5555">音高</strong>

						</p>
						<p style="text-align:left;" class="fragment fade-up">
							而要如何將矩陣序列化呢?
						</p>
					</section>

					<section>
						<img src="./img/Figure 1.png" width="70%" />
						<div class="fragment fade-up">
							等同矩陣
						</div>
						<p style="font-size: 70%" class="fragment fade-up">\begin{bmatrix}
							S_1:67 & S_2:67 & S_3:67 & S_4:67 \\[0.3em]
							A_1:62 & A_2:62 & A_3:62 & A_4:62 \\[0.3em]
							T_1:59 & T_2:59 & T_3:57 & T_4:57 \\[0.3em]
							B_1:43 & B_2:43 & B_3:45 & B_4:45
							\end{bmatrix}</p>
					</section>

					<section>
						<p style="text-align:left;">
							序列化的方式是由上而下，由左至右掃描矩陣
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							因此前面的矩陣在序列化後會變成
						</p>
						<p class="fragment fade-up">
							$$
							S_1,A_1,T_1,B_1,...,S_4,A_4,T_4,B_4
							$$
						</p>
						<p style="font-size: 70%" style="text-align:left;" class="fragment fade-up">
							註:女高音(S)，中音(A)，男高音(T)，低音(B)
						</p>
					</section>

					<section>
						<p style="text-align:left;">
							而Piano-e-Competition的資料集，則是由多聲部鋼琴曲構成
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							若用跟JSB Chorale相同的矩陣表示法
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							會導致序列過長
						</p>
					</section>

					<section>
						<p style="text-align:left;">
							因此改用Oore等人與2018提出的<a href="https://arxiv.org/abs/1808.03715">用事件表示音樂序列方法</a>
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							如下頁所表示
						</p>
					</section>

					<section>
						<img src="./img/Figure 2.png" width="70%">
						<p class="fragment fade-up">
							等同
						</p>
						<p style="font-size: 70%;text-align:left;position: relative;left:10%;" class="fragment fade-up">
							SET_VELOCITY&lt;80&gt;, NOTE_ON&lt;60&gt;,<br>
							TIME_SHIFT&lt;500&gt;, NOTE_ON&lt;64&gt;,<br>
							TIME_SHIFT&lt;500&gt;, NOTE_ON&lt;67&gt;,<br>
							TIME_SHIFT&lt;1000&gt;, NOTE_OFF&lt;60&gt;, NOTE_OFF&lt;64&gt;,<br>
							NOTE_OFF&lt;67&gt;,<br>
							TIME_SHIFT&lt;500&gt;, SET_VELOCITY&lt;100&gt;, NOTE_ON&lt;65&gt;,<br>
							TIME_SHIFT&lt;500&gt;, NOTE_OFF&lt;65&gt;
						</p>
					</section>

					<section>
						<p style="text-align:left;">
							SET_VELOCITY&lt;<strong style="color: #ff55aa">80</strong>&gt;代表將撥放速度設定為<strong
								style="color: #ff55aa">80</strong><br>
							NOTE_ON&lt;<strong style="color: #ff55aa">60</strong>&gt;代表<strong
								style="color: #ff55aa">pitch
								60</strong>將開始播放<br>

						</p>
						<p style="font-size: 70%" style="text-align:left;" class="fragment fade-up">
							註:pitch 60=C大調的C音
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							TIME_SHIFT&lt;<strong style="color: #ff55aa">500</strong>&gt;表示再來的事件將延遲<strong
								style="color: #ff55aa">500</strong>毫秒才觸發<br>
							NOTE_OFF&lt;<strong style="color: #ff55aa">60</strong>&gt;則是<strong
								style="color: #ff55aa">pitch
								60</strong>結束
						</p>
					</section>
					<section>
						<p style="text-align:left;">
							因此再回來看那一段奇怪的序列
						</p>
						<p style="font-size: 70%;text-align:left;" class="fragment fade-up">
							NOTE_ON&lt;60&gt;,<span style="color: #ff55aa"
								class="fragment fade-up">開始播放C大調的C音</span><br>
							TIME_SHIFT&lt;500&gt;, NOTE_ON&lt;64&gt;,<span style="color: #ff55aa"
								class="fragment fade-up">0.5秒後，開始播放C大調的E音</span><br>
							TIME_SHIFT&lt;500&gt;, NOTE_ON&lt;67&gt;,<span style="color: #ff55aa"
								class="fragment fade-up">1秒後，開始播放C大調的G音</span><br><br>
							TIME_SHIFT&lt;1000&gt;, NOTE_OFF&lt;60&gt;, NOTE_OFF&lt;64&gt;,NOTE_OFF&lt;67&gt;,
							<span style="color: #ff55aa" class="fragment fade-up">2秒後，結束C、E、G這幾個音</span>
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							就能理解其意義了
						</p>
					</section>

					<section>
						<p style="text-align:left;">
							使用這個方式，<br>
							讓Piano-e-Competition資料集靠
						</p>
						<ul>
							<li class="fragment fade-up">
								128個NOTE_ON
							</li>
							<li class="fragment fade-up">
								128個NOTE_OFF
							</li>
							<li class="fragment fade-up">
								100個TIME_SHIFT
							</li>
							<li class="fragment fade-up">
								32個SET_VELOCITY
							</li>
						</ul>
						<br>
						<p style="text-align:left;" class="fragment fade-up">就能表達整首音樂</p>
						<p style="text-align:left;" class="fragment fade-up">節省了許多資訊</p>
					</section>

					<section>
						<h4>背景知識</h4>
						<p class="fragment fade-up">
							Transformer
						</p>
					</section>

					<section>
						<p style="text-align:left;">
							Transformer是由google於2017年所提出
							<br>
							基於注意力機制的全新架構
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							那麼，什麼是注意力機制呢?
						</p>
					</section>

					<section>
						<p style="text-align:left;">
							注意力機制就像人類在看東西一樣
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							眼前場景各處所分布的注意力都不一致
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							只關注重要的地方，這樣就能減低多於資訊的干擾
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							增加準確度並減少運算消耗
						</p>
					</section>

					<section>
						<p style="text-align:left;">
							回到Transformer
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							Transformer是由Encoder+Decoder所構成的<br>
							<strong style="color: #ff5555">自回歸模型</strong>
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							Encoder與Decoder很相似
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							都是N層的sub layer疊合而成
						</p>
					</section>

					<section>
						<p>
							而sub layer主要是
						</p>
						<ul>
							<li class="fragment fade-up">
								self-attention
							</li>
							<li class="fragment fade-up">
								feedforward
							</li>
						</ul>
						<p class="fragment fade-up">
							這兩層
						</p>
						<p style="font-size: 70%;" class="fragment fade-up">
							註:詳細架構將不會在此解釋
						</p>
					</section>

					<section>
						<p style="text-align:left;">
							而這邊最重要的就是self-attention了
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							self-attention的公式如下
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							$$
							Attention({Q}^h,{K}^h,{V}^h)=Softmax(\frac{{Q}^h{{K}^h}^T}{\sqrt{D_h}}){V}^h
							$$
							$$
							{head}^h=Attention({Q}^h,{K}^h,{V}^h)
							$$
						</p>
					</section>
					<section>
						<p style="text-align:left;">
							至於\({Q}^h、{K}^h\)與\({V}^h\)則如下面說明
						</p>
						<ol>
							<li class="fragment fade-up">
								\(X=(x_1,x_2,...,x_{L-1},x_L)\)
								<br>
								\(x_n\)是D維詞彙向量，因此\(X\)是大小為LD的矩陣
							</li>
							<br>
							<li class="fragment fade-up">
								\(X*{W}^{Q|K|V}=Q|K|V\)
								<br>
								而\({W}^Q、{W}^K、{W}^V\)是D*D的矩陣
								<br>
								因此，\(Q\)(query)、\(K\)(key)、\(V\)(value)跟也\(X\)同樣是LD的矩陣
							</li>
						</ol>
					</section>
					<section>
						<ol start="3">
							<li>
								將\(Q、K、V\)切成\(H\)分
								<br>
								這樣每分\({Q}^h、{K}^h、{V}^h\)就會變成\(L*D_h\)
								<br>
								其中的\(D_h=\frac{D}{H}\)
							</li>
							<br>
							<li class="fragment fade-up">
								如此一來，就能讓Tansformer注意詞句的不同區塊
							</li>
						</ol>
					</section>
					<section>
						<p style="text-align:left;">
							接著，將每個\(head_h\)串接起來
							$$
							Head=Concat(head_1,head_2,...,head_h)
							$$
						</p>

						<p style="text-align:left;" class="fragment fade-up">
							就可以將\(Head\)送至FFN了
							$$
							FFN(Head)=max(0,Head*W_1+b_1)W_2+b_2
							$$
						</p>
					</section>

					<section>
						<h4>
							相對位置的self-attention
						</h4>
					</section>

					<section>
						<p style="text-align:left;">
							原版的Transformer是利用sin函數
							<br>
							來進行時序標定
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							後來Shaw等人於2018年推出相對位置標定方法
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							但其\(O({L}^2D)\)的記憶體複雜度實在不適合用在長序列的問題上
						</p>
					</section>
					<section>
						<p style="text-align:left;">
							Shaw推出的公式大致如下
						</p>
						<p class="fragment fade-up">
							$$
							RelativeAttention=Softmax(\frac{Q{K}^T+{S}^{rel}}{\sqrt{D_h}})V
							$$
						</p>
						<p style="text-align:left;" class="fragment fade-up">
							其中的\({S}^{rel}=Q{R}^T\)，\(R\)是\((L,L,D_h)\)的張量
					</section>
					<section>
						<img src="img/Figure 3.png">
						<p>
							因為張量\(R\)使得記憶體複雜度變\(O({L}^2D)\)
							<br>
							<span style="font-size: 70%">註:每個顏色代表不同相對距離，灰色則表示屏蔽或填充位置</span>
						</p>
					</section>
					<section>
						<p style="text-align:left;">
							因此，本篇論文在這提出了新的計算方式
						</p>
					</section>
					<section>
						相對全域Attention
						<img src="img/Figure 4.png">
						<p>
							利用Skew算法就能將記憶體複雜度降低至\(O(LD)\)
							<br>
						</p>
					</section>
					<section>
						<ol>
							<li>
								在\(Q{{E}^r}^T\)最左邊連接一個長度為\(L\)的虛擬陣列
						</li>
						<li class="fragment fade-up">
							將其重塑成\((L+1,L)\)的矩陣
							<ol style=" list-style-type:lower-alpha">
								<li class="fragment fade-up">
									先將其展平
								</li>
								<li class="fragment fade-up">
									每\(L\)個元素分成一份後疊合在一起
								</li>
							</ol>
						</li>
						<li class="fragment fade-up">
							替除掉第一行，即可得到\({S}^{rel}\)
						</li>
					</ol>
				</section>
				<section>
					相對區域Attention
					<img src="img/Figure 5.png">
					<p style="text-align:left;font-size:70%">
						註:有些論文中有使用Local Attention(ex:<a href="https://arxiv.org/abs/1802.05751">Image Transformer</a>、<a href="https://arxiv.org/abs/1801.10198">Generating Wikipedia by Summarizing Long Sequences</a>)，
						因此本論文在這也有提出用於Local Attention的相對關係標定方式
					</p>
				</section>
				<section>
					1.將長度為\(N\)的陣列填充至\(Q{{E}^r}^T\)最右邊的列
					<img src="img/Figure 6.png" width="60%">
				</section>
				<section>
					<p>
						2.將矩陣展平，並在尾端補上\(N-1\)個元素
						<img src="img/Figure 7.png">
					</p>
					<p class="fragment fade-up">
						3.把每\(2N-1\)個元素切成一份，再把每份堆疊起來
						<img src="img/Figure 8.png">
					</p>
				</section>
				<section>
					變成\((N+1, 2N−1)\)的矩陣
					<img src="img/Figure 9.png" width="50%">
				</section>
				<section>
					<p>
						4.將矩陣切割，取出前\(N\)行、後\(N\)列
						<br>
						即可得到\(N*N\)的矩陣\({S}^{rel}\)
					</p>
					<img src="img/Figure 10.png" width="60%">
				</section>
			</section>
			<section>
				<section>
					<h3>實驗結果&結論</h3>
					
				</section>
				<section>
					<p style="text-align:left;font-size:75%;color: rgb(255, 157, 37)">
						Note-wise validation NLL on J.S.Bach Chorales at 16th notes.
					</p>
					<table style="font-size:60%;">
						<tbody>
							<tr>
								<th>Model variation</th>
								<th>
									<nobr>Validation NLL</nobr>
								</th>
							</tr>
							<tr>
								<td>
									<nobr>COCONET (CNN, chronological, 64L, 128 3x3f)</nobr>
									<br>
									<br>
									<nobr>COCONET (CNN, orderless, 64L, 128 3x3f)</nobr>
								</td>
								<td>
									\(0.436\)
									<br>
									<br>
									\(≤{0.238}^6\)
								</td>
							</tr>
						</tbody>
					</table>
					<P style="font-size:70%;">
						<br>
						註:NLL是negative log-likelihood的縮寫
					</P>
				</section>
				<section>
					<p style="text-align:left;font-size:75%;color: rgb(255, 157, 37)">
						Note-wise validation NLL on J.S.Bach Chorales at 16th notes.
					</p>
					<table style="font-size:60%;">
						<tbody>
							<tr>
								<th>Model variation</th>
								<th>
									<nobr>Validation NLL</nobr>
								</th>
							</tr>
							<tr>
								<td>
									<nobr>Transformer (TF) baseline (Vaswani et al., 2017)<br>(5L, 256hs, 256att, 1024ff, 8h)</nobr>
									<br>
									<br>
									<nobr>TF baseline + concat positional sinusoids (cps)</nobr>
									<br>
									<br>
									<nobr>TF baseline + concat positional sinusoids,<br>instrument labels (cpsi)</nobr>
								</td>
								<td>
									\(0.417\)
									<br>
									<br>
									<br>
									\(0.398\)
									<br>
									<br>
									\(0.370\)
								</td>
							</tr>
						</tbody>
					</table>
					
				</section>
				<section>
					<p style="text-align:left;font-size:75%;color: rgb(255, 157, 37)">
						Note-wise validation NLL on J.S.Bach Chorales at 16th notes.
					</p>
					<table style="font-size:60%;">
						<tbody>
							<tr>
								<th>Model variation</th>
								<th>
									<nobr>Validation NLL</nobr>
								</th>
							</tr>
							<tr>
								<td>
									<nobr>Relative Transformer (Shaw et al., 2018)<br>(5L, 512hs, 512att, 512ff, 256r, 8h)</nobr>
									<br>
									<br>
									<nobr>Relative Transformer + concat positional sinusoids,<br>instrument labels (cpsi)</nobr>
									<br>
									<br>
									<nobr>Relative Transformer + cpsi +relative pitch and time</nobr>
								</td>
								<td>
									\(0.357\)
									<br>
									<br>
									<br>
									\(0.347\)
									<br>
									<br>
									<br>
									\(0.335\)
								</td>
							</tr>
						</tbody>
					</table>
				</section>
				<section>
					<p style="text-align:left;font-size:75%;color: rgb(255, 157, 37)">
						Validation NLL for Piano-e-Competition dataset, 
						with event-based representation with
						lengths <nobr>\(L = 2048\).</nobr> 
					</p>
					<table style="font-size:60%;">
						<tbody>
							<tr>
								<th>Model variation</th>
								<th>
									<nobr>Validation NLL</nobr>
								</th>
							</tr>
							<tr>
								<td>
									<nobr>PERFORMANCE RNN (LSTM) (3L, 1024hs)</nobr>
									<br>
									<br>
									<nobr>LSTM with attention (3L, 1024hs, 1024att)</nobr>
								</td>
								<td>
									\(1.969\)
									<br>
									<br>
									\(1.959\)
								</td>
							</tr>
						</tbody>
					</table>
				</section>
				<section>
					<p style="text-align:left;font-size:75%;color: rgb(255, 157, 37)">
						Validation NLL for Piano-e-Competition dataset,
						with event-based representation with
						lengths <nobr>\(L = 2048\).</nobr>
					</p>
					<table style="font-size:60%;">
						<tbody>
							<tr>
								<th>Model variation</th>
								<th>
									<nobr>Validation NLL</nobr>
								</th>
							</tr>
							<tr>
								<td>
									<nobr>Transformer (TF) baseline <br>(6L, 256hs, 512att, 2048fs, 1024r, 8h)</nobr>
									<br>
									<br>
									<nobr>TF with local attention <br>(Liu et al., 2018) (8L, 1024fs, 512bs)</nobr>
									<br>
									<br>
									<nobr>TF with relative global attention <br>(our efficient formulation) (6L, 2048fs, 1024r)</nobr>
									<br>
									<br>
									<nobr>TF with relative local attention (ours) <br>(6L, 1024fs, 2048r, 512bs)</nobr>
								</td>
								<td>
									\(1.861\)
									<br>
									<br>
									<br>
									\(1.863\)
									<br>
									<br>
									<br>
									<strong style="color: rgb(255, 238, 0)">\(\mathbf{1.835}\)</strong>
									<br>
									<br>
									<br>
									<strong style="color: rgb(255, 238, 0)">\(\mathbf{1.840}\)</strong>
								</td>
							</tr>
						</tbody>
					</table>
				</section>
				<section>
					<p style="text-align:left;font-size:75%;color: rgb(255, 157, 37)">
						Validation conditional
						NLL given groundtruth melody from
						Piano-e-Competition.
					</p>
					<table style="font-size:60%;">
						<tbody>
							<tr>
								<th>Model variation</th>
								<th>
									<nobr>NLL</nobr>
								</th>
							</tr>
							<tr>
								<td>
									<nobr>Baseline Transformer</nobr>
									<br>
									<br>
									<nobr>Relative Transformer (ours)</nobr>
									</td>
								<td>
									\(2.066\)
									<br>
									<br>
									\(1.786\)
								</td>
							</tr>
						</tbody>
					</table>
				</section>
				<section>
					<img src="./img/Figure 12.png">
					<p style="text-align:left;font-size: 70%;position: relative;left: 15%;">
						每種模型產生的音樂經過受測者評分後獲勝的樣品數
						<br>
						誤差線代表平均值的標準偏差
					</p>
				</section>
				<section>
					<h3>生成比較</h3>
					<img src="./img/Figure 13.png" width="5%">
					<p style="font-size: 70%">音樂原型</p>
				</section>
				<section>
					<img src="./img/Figure 14.png">
					<p style="font-size: 70%">Performance RNN, an LSTM生成結果</p>
				</section>
				<section>
					<img src="./img/Figure 15.png">
					<p style="font-size: 70%">Vanilla Transformer生成結果</p>
				</section>
				<section>
					<img src="./img/Figure 16.png">
					<p style="font-size: 70%">Music Transformer生成結果</p>
				</section>
				<section>
					<h4>結論</h4>
				</section>
				<section>
					<p style="text-align:left;">
						本實驗證明了使用相對注意力機制的Transformer能勝任音樂生成這項工作
					</p>
					<p style="text-align:left;" class="fragment fade-up">
						它在原音的基礎上生成音樂的能力
						<br>
						也使其有做為音樂創作工具的可能性
					</p>
				</section>
				<section>
					<p style="text-align:left;">
						相對注意力機制也改善了Transformer的缺陷
					</p>
					<p style="text-align:left;" class="fragment fade-up">
						使Transformer獲得了
						<br>
						可以捕捉不同週期性特徵的能力
					</p>
				</section>
				<section>
					<p style="text-align:left;">
						且大幅下降的記憶體複雜度使此方法
						<br>
						能處理更長的序列
					</p>
					<p style="text-align:left;" class="fragment fade-up">
						大幅增加了其應用範圍
					</p>
				</section>
			</section>

			<section>
				<section>
					<h3>心得</h3>
				</section>
				<section>
					<p style="text-align:left;">
						雖然是在了解Transformer架構的情況下來看這篇論文
					</p>
					<p style="text-align:left;" class="fragment fade-up">
						但還是覺得有些地方蠻難懂的
					</p>
				</section>
				<section>
					<p style="text-align:left;">
						不過在看完之後
					</p>
					<p style="text-align:left;" class="fragment fade-up">
						才知道原來以前我不太注重的記憶體複雜度對解決問題有這麼大的影響
					</p>
				</section>
				<section>
					<p style="text-align:left;">
						然後是，有種想在以後實作看看音樂生成器的衝動
					</p>
					<p style="text-align:left;" class="fragment fade-up">
						順便能比較看看<nobr>Music Transformer</nobr>與<nobr><a href="https://arxiv.org/abs/1901.02860">Transformer-XL</a></nobr>的相對注意力機制
						<br>
						(兩者方法不同)實際應用上的區別
					</p>
				</section>
			</section>

				<section>
					<section>
						<h3>參考資料</h3>
						<p style="font-size: 70%;text-align:left;">
							[1]<a href="https://arxiv.org/abs/1809.04281"  style="position: absolute;left: 6%;">[1809.04281] Music Transformer - arXiv</a>
							<br>
							<br>
							[2]<a href="https://magenta.tensorflow.org/music-transformer" style="position: absolute;left: 6%;">Music Transformer: Generating Music with Long-Term Structure</a>
							<br>
							<br>
							<br>
							[3]<a href="https://www.youtube.com/watch?v=5vcj8kSwBCY&list=LLWZEA5o8OGtqZDWmCWHfWIg&index=2&t=2592s" style="position: absolute;left: 6%;">Stanford CS224N: NLP with Deep Learning | Winter 2019 | Lecture 14 – Transformers and Self-Attention</a>
						</p>
					</section>
				</section>

			<section id="transitions">
				<h2>Transition Styles</h2>
				<p>
					You can select from different transitions, like: <br>
					<a href="?transition=none#/transitions">None</a> -
					<a href="?transition=fade#/transitions">Fade</a> -
					<a href="?transition=slide#/transitions">Slide</a> -
					<a href="?transition=convex#/transitions">Convex</a> -
					<a href="?transition=concave#/transitions">Concave</a> -
					<a href="?transition=zoom#/transitions">Zoom</a>
				</p>
			</section>

			<section id="themes">
				<h2>Themes</h2>
				<p>
					reveal.js comes with a few themes built in: <br>
					<!-- Hacks to swap themes after the page has loaded. Not flexible and only intended for the reveal.js demo deck. -->
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/black.css'); return false;">Black
						(default)</a> -
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/white.css'); return false;">White</a>
					-
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/league.css'); return false;">League</a>
					-
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/sky.css'); return false;">Sky</a>
					-
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/beige.css'); return false;">Beige</a>
					-
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/simple.css'); return false;">Simple</a>
					<br>
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/serif.css'); return false;">Serif</a>
					-
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/blood.css'); return false;">Blood</a>
					-
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/night.css'); return false;">Night</a>
					-
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/moon.css'); return false;">Moon</a>
					-
					<a href="#"
						onclick="document.getElementById('theme').setAttribute('href','css/theme/solarized.css'); return false;">Solarized</a>
				</p>
			</section>
		</div>

	</div>

	<script src="js/reveal.js"></script>

	<script>

		// More info https://github.com/hakimel/reveal.js#configuration
		Reveal.initialize({
			controls: true,
			progress: true,
			center: true,
			hash: true,

			transition: 'slide', // none/fade/slide/convex/concave/zoom

			// More info https://github.com/hakimel/reveal.js#dependencies
			dependencies: [
				{ src: 'plugin/markdown/marked.js', condition: function () { return !!document.querySelector('[data-markdown]'); } },
				{ src: 'plugin/markdown/markdown.js', condition: function () { return !!document.querySelector('[data-markdown]'); } },
				{ src: 'plugin/highlight/highlight.js', async: true },
				{ src: 'plugin/search/search.js', async: true },
				{ src: 'plugin/zoom-js/zoom.js', async: true },
				{ src: 'plugin/notes/notes.js', async: true }
			]
		});

	</script>

</body>

</html>